{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mltpqcKKoLY5"
      },
      "source": [
        "1. Wstęp\n",
        "- Importy bibliotek\n",
        "- pobranie bazy ze zdjęciami\n",
        "- import modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEP7Btj6bTpf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLV6YpUDoQjG"
      },
      "source": [
        "2. Zasada działania Grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emSCG7xEatW8"
      },
      "outputs": [],
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with respect to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with respect to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Function to overlay a heatmap on an image\n",
        "def overlay_heatmap(heatmap, image_np, alpha=0.4):\n",
        "    if heatmap.shape != image_np.shape[0:2]:\n",
        "        heatmap = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap * alpha + image_np\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
        "    return superimposed_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZVsqf4oavbF"
      },
      "source": [
        "3. Omówienie wybranego modelu i zastosowanie go w Grad-cam\n",
        "\n",
        "Wykorzystywany model dla Grad-cam: ResNet50\n",
        "\n",
        "Dzieki wybranemu modelowi grad-cam może poprawnie określać pixele odpowiadające zwierzętom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4q1UYIfa_l-"
      },
      "outputs": [],
      "source": [
        "classification_model = ResNet50(weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv7PXZN3bLm7"
      },
      "source": [
        "Przykład zastosowania modelu w grad-cam na obrazie przedstawiającym dwa lwy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgWvW-I0bKtf"
      },
      "outputs": [],
      "source": [
        "path_to_image = \"lions.png\"\n",
        "image_example = cv2.imread(path_to_image)\n",
        "image_example = cv2.cvtColor(image_example, cv2.COLOR_BGR2RGB)\n",
        "image_example = cv2.resize(image_example, (224, 224))\n",
        "\n",
        "image_example_preprocessed = preprocess_input(np.expand_dims(image_example, axis=0))\n",
        "heatmap = make_gradcam_heatmap(image_example_preprocessed, classification_model, \"conv5_block3_out\")\n",
        "overlayed_image = overlay_heatmap(heatmap, image_example)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "plt.imshow(overlayed_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fdxtrV4ceE9"
      },
      "source": [
        "4. Połączenie Grad-cam (dla uproszczenia grad-cam z wybranym przez nas modelem będzie nazywany jako grad-cam) z modelem wykrywającym zwierzęta na obrazie.\n",
        "\n",
        "Powodem takiego połąćzenia jest fakt iż grad-cam wykrywa zazwyczaj jeden konkretny element a podając mu model wykrywający i klasyfikujący wiele zaczyna działąć niepoprawnie.\n",
        "\n",
        "Celem tego połączenia jest również wskazanie w jaki sposób grad cam przedstawi heatmap'ę dla wykrytych wcześniej wycinków obrazu.\n",
        "\n",
        "Poniżej przedstawiony został kod programu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E48aPuMQcYxA"
      },
      "outputs": [],
      "source": [
        "def animals_detection(path_to_image):\n",
        "  detector_model_url = \"https://tfhub.dev/tensorflow/efficientdet/lite4/detection/1\"\n",
        "  detector = hub.load(detector_model_url)\n",
        "\n",
        "  # Load and preprocess the image\n",
        "  image_path = path_to_image\n",
        "  image_np = cv2.imread(image_path)\n",
        "  image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Run object detection\n",
        "  detections = detector(image_np[np.newaxis, ...])\n",
        "\n",
        "  detection_boxes = detections[0].numpy()\n",
        "  detection_classes = detections[2].numpy()\n",
        "  detection_scores = detections[1].numpy()\n",
        "  num_detections = int(detections[3][0].numpy())\n",
        "\n",
        "  for i in range(num_detections):\n",
        "      box = detection_boxes[0, i]\n",
        "      class_id = int(detection_classes[0, i])\n",
        "      score = detection_scores[0, i]\n",
        "\n",
        "      image_height, image_width, _ = image_np.shape\n",
        "\n",
        "      if score > 0.3:\n",
        "          ymin, xmin, ymax, xmax = box\n",
        "          ymin = int(ymin)\n",
        "          xmin = int(xmin)\n",
        "          ymax = int(ymax)\n",
        "          xmax = int(xmax)\n",
        "\n",
        "          # Skip the box if it has zero area\n",
        "          print(xmin, xmax, ymax, ymin)\n",
        "          if (xmax <= xmin) or (ymax <= ymin):\n",
        "              continue\n",
        "\n",
        "          # Crop and preprocess the image for the classification model\n",
        "          crop_img = image_np[ymin:ymax, xmin:xmax]\n",
        "          crop_img_resized = cv2.resize(crop_img, (224, 224))\n",
        "          crop_img_preprocessed = preprocess_input(np.expand_dims(crop_img_resized, axis=0))\n",
        "\n",
        "          # Get the classification label\n",
        "          preds = classification_model.predict(crop_img_preprocessed)\n",
        "          label = decode_predictions(preds, top=1)[0][0][1]\n",
        "\n",
        "          # Get Grad-CAM heatmap\n",
        "          heatmap = make_gradcam_heatmap(crop_img_preprocessed, classification_model, \"conv5_block3_out\")\n",
        "\n",
        "          # Resize heatmap to the size of the crop\n",
        "          heatmap_resized = cv2.resize(heatmap, (xmax - xmin, ymax - ymin))\n",
        "\n",
        "          # Overlay heatmap on the original cropped image\n",
        "          overlay_on_crop = overlay_heatmap(heatmap_resized, crop_img)\n",
        "\n",
        "          plt.figure(figsize=(10, 15))\n",
        "          plt.subplot(1, 3, 1)\n",
        "          plt.imshow(crop_img)\n",
        "          plt.title('Wycinek obrazu')\n",
        "          plt.subplot(1, 3, 2)\n",
        "          plt.title('Heatmap dla wycinka obrazu')\n",
        "          plt.imshow(heatmap_resized)\n",
        "          plt.axis('off')\n",
        "          plt.subplot(1, 3, 3)\n",
        "          plt.imshow(overlay_on_crop)\n",
        "          plt.title('Heatmap nałożona na wycinek obrazu')\n",
        "          plt.subplots_adjust(wspace=0.5)\n",
        "          plt.show()\n",
        "\n",
        "          # Replace the cropped area with the overlay heatmap\n",
        "          image_np[ymin:ymax, xmin:xmax] = overlay_on_crop\n",
        "\n",
        "  # Display the final image with bounding boxes and Grad-CAM heatmaps\n",
        "  plt.figure(figsize=(10, 15))\n",
        "  plt.imshow(image_np)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5rZheZHpszf"
      },
      "source": [
        "5. Zadanie dla grupy - pradopodobnie samodzielne wybranie zdjęcia i wykorzystanie zaimplementowanych algorytmów w celu sprawdzenia modelu.\n",
        "\n",
        "Przykładowe wybrane zdjęcie przedstawione zostało poniżej. W celu wykorzystania danego zdjęcia w progranie wymagane jest pobranie go a następnie podanie ścieżki do niego jako argument do funcji animals_detection(ścieżka)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECCS4g4GeTUc"
      },
      "outputs": [],
      "source": [
        "animals_detection(\"animals_2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yvzxA7czmjSU"
      },
      "outputs": [],
      "source": [
        "layers = []\n",
        "for layer in classification_model.layers:\n",
        "    name = layer.name\n",
        "    if len(name) > 2 and name[-3:] == \"out\":\n",
        "      layers.append(name)\n",
        "\n",
        "def show_image_on_layer_with_heatmap(image_path, layer):\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_fixed = cv2.resize(image, (224, 224))\n",
        "  image_fixed = preprocess_input(np.expand_dims(image_fixed, axis=0))\n",
        "  heatmap = make_gradcam_heatmap(image_fixed, classification_model, layer)\n",
        "  heatmap_fixed = fix_heatmap(heatmap, image)\n",
        "  show_image_heatmap_mixed(image, heatmap, layer)\n",
        "\n",
        "def show_image_heatmap_mixed(image, heatmap, label):\n",
        "  plt.figure(figsize=(10, 15))\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.imshow(image)\n",
        "  plt.title('obraz')\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.title(f'Heatmap\\nlayer: {label}')\n",
        "  plt.imshow(heatmap)\n",
        "  plt.axis('off')\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.imshow(overlay_heatmap(heatmap, image))\n",
        "  plt.title(f'obraz + heatmap\\nlayer: {label}')\n",
        "  plt.subplots_adjust(wspace=0.5)\n",
        "  plt.show()\n",
        "\n",
        "def fix_heatmap(heatmap, image):\n",
        "  return cv2.resize(heatmap, (image.shape[0], image.shape[1]))\n",
        "\n",
        "def show_all_layers_heatmap(image_path):\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_fixed = cv2.resize(image, (224, 224))\n",
        "  image_fixed = preprocess_input(np.expand_dims(image_fixed, axis=0))\n",
        "  for layer in classification_model.layers[2:]:\n",
        "    try:\n",
        "      heatmap = make_gradcam_heatmap(image_fixed, classification_model, layer.name)\n",
        "    finally:\n",
        "      heatmap_fixed = fix_heatmap(heatmap, image)\n",
        "      show_image_heatmap_mixed(image, heatmap, layer.name)\n",
        "\n",
        "show_all_layers_heatmap(\"lion.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVrGlIFebjql"
      },
      "source": [
        "Zadanie 1\n",
        "\n",
        "Dla wybranego przez siebie obrazka wyświetl wszystkie możliwe heatmapy (wszystkie dla warst wyjściowych modelu klasyfikującego)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qv1IFygdgTtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zadanie 2\n",
        "\n",
        "Wybierz najbardziej odpowiednią heatmapę dla wybranego przez siebie obrazka i wyświetl nałożenie heatmapy na obraz za pomocą funkcji"
      ],
      "metadata": {
        "id": "ci9HuUiXgT_z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GJl4PYogUxh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}